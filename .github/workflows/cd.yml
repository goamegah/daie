name: CD - Déploiement Databricks

on:
  workflow_dispatch:
    inputs:
      environment:
        description: 'Environnement de déploiement'
        required: true
        default: 'dev'
        type: choice
        options: [dev, test, prod]

      developer_name:
        description: 'Nom du développeur (ex: godwin)'
        required: false
        default: 'dev'
        type: string

      skip_tests:
        description: 'Ignorer les tests (uniquement pour dev)'
        required: false
        default: false
        type: boolean

env:
  PYTHON_VERSION: '3.11'
  CATALOG_PREFIX: 'daie_chn'

permissions:
  contents: read

# ============================================================
# TESTS
# ============================================================
jobs:
  test:
    name: Tests avant déploiement
    runs-on: ubuntu-latest
    if: ${{ !(github.event.inputs.environment == 'dev' && github.event.inputs.skip_tests == 'true') }}

    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: pip

      - uses: actions/setup-java@v4
        with:
          distribution: temurin
          java-version: '11'

      - name: Install test dependencies
        run: |
          pip install -U pip
          pip install -r test-requirements.txt
          pip install -e . --no-deps

      - name: Run tests
        run: pytest tests/ -v

# ============================================================
# BUILD
# ============================================================
  build:
    name: Build wheel
    runs-on: ubuntu-latest
    needs: test
    if: always() && (needs.test.result == 'success' || needs.test.result == 'skipped')

    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: pip

      - name: Build package
        run: |
          pip install -U pip build wheel
          python -m build

      - uses: actions/upload-artifact@v4
        with:
          name: python-wheel
          path: dist/
          retention-days: 7

# ============================================================
# DEPLOY
# ============================================================
  deploy:
    name: Déploiement Databricks
    runs-on: ubuntu-latest
    needs: build
    environment: ${{ github.event.inputs.environment }}

    env:
      ENV_NAME: ${{ github.event.inputs.environment }}
      DEVELOPER_NAME: ${{ github.event.inputs.developer_name }}
      DATABRICKS_HOST: ${{ vars.DATABRICKS_HOST }}

      ARM_CLIENT_ID: ${{ secrets.ARM_CLIENT_ID }}
      ARM_CLIENT_SECRET: ${{ secrets.ARM_CLIENT_SECRET }}
      ARM_TENANT_ID: ${{ secrets.ARM_TENANT_ID }}

    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - uses: actions/download-artifact@v4
        with:
          name: python-wheel
          path: dist/

      # --------------------------------------------------------
      # Databricks CLI v2 (Python module only)
      # --------------------------------------------------------
      - name: Install Databricks CLI v2
        run: |
          pip install -U pip
          pip uninstall -y databricks-cli || true
          pip install -U databricks databricks-sdk
          python -m databricks --version

      # --------------------------------------------------------
      # Auth Azure AD - Service Principal
      # --------------------------------------------------------
      - name: Configure Databricks auth (Azure AD SP)
        run: |
          cat <<EOF > ~/.databrickscfg
          [DEFAULT]
          host = ${DATABRICKS_HOST}
          azure_client_id = ${ARM_CLIENT_ID}
          azure_client_secret = ${ARM_CLIENT_SECRET}
          azure_tenant_id = ${ARM_TENANT_ID}
          EOF

          python -m databricks workspace list || true

      # --------------------------------------------------------
      # Compute deployment paths
      # --------------------------------------------------------
      - name: Compute deployment variables
        id: vars
        run: |
          BRONZE_CATALOG="${CATALOG_PREFIX}_${ENV_NAME}_bronze"
          VOLUME_PATH="/Volumes/${BRONZE_CATALOG}/artifacts/packages/${DEVELOPER_NAME}"

          echo "BRONZE_CATALOG=$BRONZE_CATALOG" >> $GITHUB_OUTPUT
          echo "VOLUME_PATH=$VOLUME_PATH" >> $GITHUB_OUTPUT

      # --------------------------------------------------------
      # Upload wheel to Unity Catalog Volume
      # --------------------------------------------------------
      - name: Upload wheel to Unity Catalog Volume
        run: |
          set -e
          WHEEL=$(ls dist/*.whl | head -1)
          VOLUME="${{ steps.vars.outputs.VOLUME_PATH }}"

          echo "Uploading $WHEEL to $VOLUME"

          python -m databricks fs mkdirs "dbfs:$VOLUME"
          python -m databricks fs cp "$WHEEL" "dbfs:$VOLUME/" --overwrite
          python -m databricks fs ls "dbfs:$VOLUME"

      # --------------------------------------------------------
      # Summary
      # --------------------------------------------------------
      - name: Deployment summary
        run: |
          echo "=========================================="
          echo "✅ DÉPLOIEMENT TERMINÉ"
          echo "=========================================="
          echo "Environment : $ENV_NAME"
          echo "Developer   : $DEVELOPER_NAME"
          echo "Catalog     : ${{ steps.vars.outputs.BRONZE_CATALOG }}"
          echo "Volume      : ${{ steps.vars.outputs.VOLUME_PATH }}"
          echo "Commit      : ${{ github.sha }}"
          echo "Actor       : ${{ github.actor }}"
          echo "=========================================="
