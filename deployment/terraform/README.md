# Infrastructure Terraform

## ğŸ“‹ ResponsabilitÃ©s

### âœ… GÃ©rÃ© par Terraform
- Resource Group
- Storage Account & Containers
- Databricks Workspace
- Databricks Access Connector
- Key Vault
- Unity Catalog :
  - Storage Credentials
  - External Locations
  - Catalogs (Bronze, Silver, Gold)
  - Schemas & Volumes
  - Service Principal & Grants

### âŒ NON gÃ©rÃ© par Terraform
- **Clusters Databricks** â†’ GÃ©rÃ©s par le pipeline CD
  - CrÃ©ation/suppression Ã  la demande
  - Configuration dynamique par dÃ©veloppeur
  - Voir `deployment/devops/manage_cluster.py`

## ğŸš€ DÃ©ploiement

### PrÃ©requis
```bash
# Installer Terraform
# Configurer Azure CLI
az login

# Configurer les variables d'environnement
export ARM_CLIENT_ID="..."
export ARM_CLIENT_SECRET="..."
export ARM_TENANT_ID="..."
export ARM_SUBSCRIPTION_ID="..."
```

### DÃ©ployer l'infrastructure

```bash
cd deployment/terraform/dev

# Initialiser Terraform
terraform init

# Planifier les changements
terraform plan -var-file="vars/dev.tfvars"

# Appliquer les changements
terraform apply -var-file="vars/dev.tfvars"
```

## ğŸ“ Structure

```
deployment/terraform/dev/
â”œâ”€â”€ backend.tf           # Configuration du backend Terraform
â”œâ”€â”€ main.tf             # Ressources Azure principales
â”œâ”€â”€ providers.tf        # Configuration des providers
â”œâ”€â”€ variables.tf        # DÃ©claration des variables
â”œâ”€â”€ outputs.tf          # Outputs Terraform
â”œâ”€â”€ kv.tf              # Key Vault
â”œâ”€â”€ unity_catalog.tf   # Unity Catalog (Catalogs, Volumes, Grants)
â”œâ”€â”€ null.tf            # Null resources (scripts manuels)
â””â”€â”€ vars/
    â””â”€â”€ dev.tfvars     # Valeurs des variables pour dev
```

## ğŸ”§ Variables

### Obligatoires (dans dev.tfvars)
- `environment` - Environnement (dev/test/prod)
- `project` - Nom du projet
- `sp_client_id` - Client ID du Service Principal
- `sp_object_id` - Object ID du Service Principal
- `databricks_account_id` - ID du compte Databricks

### Optionnelles (avec valeurs par dÃ©faut)
- `location` - RÃ©gion Azure (dÃ©faut: westeurope)
- `databricks_sku` - SKU Databricks (dÃ©faut: premium)
- `storage_account_tier` - Tier du Storage (dÃ©faut: Standard)
- `storage_replication_type` - Type de rÃ©plication (dÃ©faut: LRS)

## ğŸ¯ Workflow

### 1. Infrastructure initiale (une fois)
```bash
cd deployment/terraform/dev
terraform apply -var-file="vars/dev.tfvars"
```

### 2. DÃ©ploiement du code (quotidien)
```bash
# Via GitHub Actions
# Actions > CD - DÃ©ploiement Databricks
# - DÃ©ployer le package
# - CrÃ©er/mettre Ã  jour le cluster
# - Installer sur les clusters
```

### 3. Mise Ã  jour de l'infrastructure (rare)
```bash
# Modifier les fichiers .tf ou dev.tfvars
terraform plan -var-file="vars/dev.tfvars"
terraform apply -var-file="vars/dev.tfvars"
```

## ğŸ“ Notes importantes

### Unity Catalog
- Le metastore doit Ãªtre crÃ©Ã© et assignÃ© manuellement par un admin compte Databricks
- Une fois assignÃ©, dÃ©commenter les ressources dans `unity_catalog.tf`

### Service Principal
- CrÃ©Ã© manuellement dans Entra ID
- AjoutÃ© dans Databricks via Terraform
- Permissions configurÃ©es automatiquement via Grants

### Clusters
- **Ne PAS crÃ©er de clusters dans Terraform**
- Utiliser le pipeline CD : `python deployment/devops/manage_cluster.py`
- Avantages : flexibilitÃ©, isolation par dÃ©veloppeur, Ã©conomies

## ğŸ” VÃ©rification

```bash
# Lister les ressources
terraform state list

# Voir les outputs
terraform output

# VÃ©rifier un volume
terraform state show databricks_volume.packages
```

## ğŸ§¹ Nettoyage

```bash
# Supprimer toute l'infrastructure (ATTENTION!)
terraform destroy -var-file="vars/dev.tfvars"
```

## ğŸ“š Documentation

- [Terraform Databricks Provider](https://registry.terraform.io/providers/databricks/databricks/latest/docs)
- [Azure Provider](https://registry.terraform.io/providers/hashicorp/azurerm/latest/docs)
- [Unity Catalog](https://docs.databricks.com/data-governance/unity-catalog/index.html)
