# Service Principal Permissions Management

## Probl√®me

Pour utiliser un Service Principal comme "Run as" dans les jobs Databricks, vous devez avoir la permission **CAN_USE** sur ce SP.

**Erreur typique:**
```
You cannot set the job's identity to <sp-id> because you do not have the required permissions.
Users with the Service Principal Manager role do not inherit the Service Principal User role.
```

## Solution

Le script `grant_sp_permissions.py` vous permet de vous accorder la permission CAN_USE sur le Service Principal.

## Utilisation

### Via Pipeline (Recommand√© pour la premi√®re fois)

1. Aller dans **Actions** > **CD - D√©ploiement Databricks**
2. Cliquer **Run workflow**
3. Cocher **üîë S'accorder permission CAN_USE sur le SP**
4. Lancer le workflow

**Note**: √Ä faire **une seule fois par d√©veloppeur**. Une fois la permission accord√©e, elle reste active.

### Via Script Local

```bash
python deployment/devops/grant_sp_permissions.py dev
```

**Variables d'environnement requises:**
- `DATABRICKS_HOST`
- `AZURE_CLIENT_ID`
- `AZURE_CLIENT_SECRET`
- `AZURE_TENANT_ID`

## Workflow Complet (Premi√®re Configuration)

Pour configurer compl√®tement l'utilisation du SP dans les jobs:

### √âtape 1: S'accorder la permission CAN_USE
```bash
python deployment/devops/grant_sp_permissions.py dev
```
‚úÖ Vous pouvez maintenant utiliser le SP comme "Run as"

### √âtape 2: Transf√©rer l'ownership des jobs
```bash
python deployment/devops/transfer_jobs_ownership.py dev
```
‚úÖ Le SP devient owner de tous les jobs

### √âtape 3: Configurer "Run as" dans les jobs
1. Aller dans le job Databricks
2. **Edit** > **Advanced** > **Run as**
3. S√©lectionner **Service Principal**
4. Choisir: `SP GitHub Actions - dev`
5. **Save**

‚úÖ Le job s'ex√©cute maintenant avec l'identit√© du SP

## Via Pipeline (Tout en une fois)

Vous pouvez aussi tout faire via le pipeline:

1. Actions > CD - D√©ploiement Databricks
2. Cocher:
   - ‚úÖ **üîë S'accorder permission CAN_USE sur le SP**
   - ‚úÖ **üîê Transf√©rer ownership des jobs au SP**
3. Lancer

Ensuite, configurez manuellement "Run as" dans chaque job (√©tape 3 ci-dessus).

## Fr√©quence d'utilisation

- **grant_sp_permissions.py**: Une seule fois par d√©veloppeur
- **transfer_jobs_ownership.py**: √Ä chaque fois que vous cr√©ez de nouveaux jobs

## Permissions accord√©es

Le script accorde **CAN_USE** qui permet:
- ‚úÖ Utiliser le SP comme "Run as" dans les jobs
- ‚úÖ Ex√©cuter des jobs avec l'identit√© du SP
- ‚ùå Ne permet PAS de modifier le SP lui-m√™me

## S√©curit√©

Le script utilise les credentials du SP pour s'accorder des permissions √† lui-m√™me. C'est s√©curis√© car:
- Le SP peut g√©rer ses propres permissions
- Seuls les users autoris√©s ont acc√®s aux credentials du SP (via GitHub Secrets)
- La permission CAN_USE est limit√©e (pas de modification du SP)

## Troubleshooting

**Erreur: "Service Principal not found"**
- V√©rifiez que le SP existe dans Databricks
- V√©rifiez que Terraform a bien cr√©√© le SP

**Erreur: "Permission denied"**
- Le SP n'a pas le droit de modifier ses propres permissions
- Contactez un admin workspace

**La permission ne fonctionne pas**
- D√©connectez-vous et reconnectez-vous √† Databricks UI
- Attendez quelques secondes (propagation des permissions)
