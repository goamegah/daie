# Transfer Jobs Ownership to Service Principal

## Pourquoi transf√©rer l'ownership?

**Best Practice**: Les jobs Databricks doivent √™tre owned par un Service Principal plut√¥t qu'un utilisateur pour:
- ‚úÖ **Automatisation**: Pas de d√©pendance aux comptes utilisateurs
- ‚úÖ **S√©curit√©**: Permissions contr√¥l√©es et auditables
- ‚úÖ **Stabilit√©**: Les jobs continuent de fonctionner m√™me si l'utilisateur quitte l'√©quipe
- ‚úÖ **Coh√©rence**: Tous les jobs utilisent la m√™me identit√©

## Utilisation

### Via Pipeline (Recommand√©)

1. Aller dans **Actions** > **CD - D√©ploiement Databricks**
2. Cliquer **Run workflow**
3. Cocher **üîê Transf√©rer ownership des jobs au SP**
4. Lancer le workflow

Le script transf√®re automatiquement l'ownership de tous les jobs du d√©veloppeur au Service Principal.

### Via Script Local

```bash
# Transf√©rer tous les jobs de l'environnement
python deployment/devops/transfer_jobs_ownership.py dev

# Transf√©rer uniquement les jobs d'un d√©veloppeur sp√©cifique
python deployment/devops/transfer_jobs_ownership.py dev john
```

**Variables d'environnement requises:**
- `DATABRICKS_HOST`
- `AZURE_CLIENT_ID`
- `AZURE_CLIENT_SECRET`
- `AZURE_TENANT_ID`

## Que fait le script?

1. **Liste les jobs** (filtr√©s par tag Developer si sp√©cifi√©)
2. **Transf√®re l'ownership** au Service Principal
3. **Donne CAN_MANAGE** au groupe admins (backup)

## Apr√®s le transfert

Une fois l'ownership transf√©r√©, vous devez mettre √† jour la configuration du job:

1. Aller dans le job Databricks
2. **Edit** > **Advanced** > **Run as**
3. S√©lectionner **Service Principal**
4. Choisir: `SP GitHub Actions - dev` (ou votre SP)
5. **Save**

Le job s'ex√©cutera maintenant avec l'identit√© du Service Principal qui a:
- ‚úÖ Permissions Unity Catalog (catalogs, volumes, external locations)
- ‚úÖ Permissions Storage (Storage Blob Data Contributor)
- ‚úÖ Permissions cluster (create, manage)

## Filtrage par Developer

Le script filtre automatiquement les jobs par le tag `Developer` si sp√©cifi√©.

**Pour que √ßa fonctionne**, vos jobs doivent avoir le tag:
```python
# Lors de la cr√©ation du job
tags = {
    "Developer": "john",
    "Environment": "dev"
}
```

## Permissions requises

Le script n√©cessite que l'utilisateur qui l'ex√©cute ait:
- Permission **CAN_MANAGE** sur les jobs √† transf√©rer
- Ou √™tre **admin** du workspace

## Troubleshooting

**Erreur: "You do not have the required permissions"**
- Vous n'√™tes pas owner/admin du job
- Demandez √† l'owner actuel de transf√©rer l'ownership

**Erreur: "Service Principal not found"**
- Le SP n'existe pas dans le workspace
- V√©rifiez que Terraform a bien cr√©√© le SP

**Jobs ne s'ex√©cutent pas apr√®s transfert**
- V√©rifiez que "Run as" est configur√© sur le SP
- V√©rifiez les permissions storage du SP (Storage Blob Data Contributor)
