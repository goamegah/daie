# Transfer Jobs Ownership to Service Principal

## Pourquoi transf√©rer l'ownership?

**Best Practice**: Les jobs Databricks doivent √™tre owned par un Service Principal plut√¥t qu'un utilisateur pour:
- ‚úÖ **Automatisation**: Pas de d√©pendance aux comptes utilisateurs
- ‚úÖ **S√©curit√©**: Permissions contr√¥l√©es et auditables
- ‚úÖ **Stabilit√©**: Les jobs continuent de fonctionner m√™me si l'utilisateur quitte l'√©quipe
- ‚úÖ **Coh√©rence**: Tous les jobs utilisent la m√™me identit√© (SP partag√©)

**Architecture**: Le Service Principal est **partag√© par tous les d√©veloppeurs** de l'environnement. Tous les jobs doivent lui appartenir.

## Utilisation

### Via Pipeline (Recommand√©)

1. Aller dans **Actions** > **CD - D√©ploiement Databricks**
2. Cliquer **Run workflow**
3. Cocher **üîê Transf√©rer ownership des jobs au SP**
4. Lancer le workflow

Le script transf√®re automatiquement l'ownership de **TOUS les jobs** de l'environnement au Service Principal.

### Via Script Local

```bash
# Transf√©rer TOUS les jobs de l'environnement
python deployment/devops/transfer_jobs_ownership.py dev
python deployment/devops/transfer_jobs_ownership.py prod
```

**Variables d'environnement requises:**
- `DATABRICKS_HOST`
- `AZURE_CLIENT_ID`
- `AZURE_CLIENT_SECRET`
- `AZURE_TENANT_ID`

## Que fait le script?

1. **Liste TOUS les jobs** de l'environnement (pas de filtrage)
2. **Transf√®re l'ownership** au Service Principal
3. **Donne CAN_MANAGE** au groupe admins (backup)

**Note**: Le script transf√®re tous les jobs, peu importe qui les a cr√©√©s ou s'ils ont des tags.

## Apr√®s le transfert

Une fois l'ownership transf√©r√©, vous devez mettre √† jour la configuration du job:

1. Aller dans le job Databricks
2. **Edit** > **Advanced** > **Run as**
3. S√©lectionner **Service Principal**
4. Choisir: `SP GitHub Actions - dev` (ou votre SP)
5. **Save**

Le job s'ex√©cutera maintenant avec l'identit√© du Service Principal qui a:
- ‚úÖ Permissions Unity Catalog (catalogs, volumes, external locations)
- ‚úÖ Permissions Storage (Storage Blob Data Contributor)
- ‚úÖ Permissions cluster (create, manage)

## Architecture

**Service Principal partag√©**: Un seul SP par environnement, utilis√© par tous les d√©veloppeurs.

**S√©paration des responsabilit√©s**:
- **Packages/Artifacts**: Isol√©s par d√©veloppeur (`/Volumes/.../packages/{developer}/`)
- **Clusters**: Isol√©s par d√©veloppeur (tag `Developer`)
- **Jobs/Workflows**: Partag√©s, tous owned par le SP

Cette architecture permet:
- ‚úÖ Chaque dev a son espace de travail (packages, clusters)
- ‚úÖ Tous les jobs utilisent la m√™me identit√© s√©curis√©e (SP)
- ‚úÖ Pas de d√©pendance aux comptes utilisateurs individuels

## Permissions requises

Le script n√©cessite que l'utilisateur qui l'ex√©cute ait:
- Permission **CAN_MANAGE** sur les jobs √† transf√©rer
- Ou √™tre **admin** du workspace

## Troubleshooting

**Erreur: "You do not have the required permissions"**
- Vous n'√™tes pas owner/admin du job
- Demandez √† l'owner actuel de transf√©rer l'ownership

**Erreur: "Service Principal not found"**
- Le SP n'existe pas dans le workspace
- V√©rifiez que Terraform a bien cr√©√© le SP

**Jobs ne s'ex√©cutent pas apr√®s transfert**
- V√©rifiez que "Run as" est configur√© sur le SP
- V√©rifiez les permissions storage du SP (Storage Blob Data Contributor)
